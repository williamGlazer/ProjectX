{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n"
   ]
  },
  {
   "source": [
    "\n",
    "$r = \\text{NBR_cas}''(t)$\n",
    "\n",
    "$AVG\\ P(r>0)$ sur 14 J\n",
    "\n",
    "$AVG\\ P(r==0)$ sur 14 J\n",
    "\n",
    "$AVG\\ P(r<0)$ sur 14 J\n",
    "\n",
    "Output $\\rightarrow$ \\[-1, 1\\]\n",
    "\n",
    "ECART-type $\\rightarrow$ certitude"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       shapeID       date  mobility_transit_stations  \\\n",
       "12582    10003 2020-03-29                      -42.0   \n",
       "12583    10003 2020-03-30                      -39.0   \n",
       "12584    10003 2020-03-31                      -40.0   \n",
       "12585    10003 2020-04-01                      -56.0   \n",
       "12586    10003 2020-04-02                      -52.0   \n",
       "...        ...        ...                        ...   \n",
       "29557    55133 2020-11-16                      -31.0   \n",
       "29558    55133 2020-11-17                      -34.5   \n",
       "29559    55133 2020-11-18                      -38.0   \n",
       "29560    55133 2020-11-19                      -26.0   \n",
       "29561    55133 2020-11-20                      -29.0   \n",
       "\n",
       "       mobility_retail_and_recreation  mobility_grocery_and_pharmacy  \\\n",
       "12582                           -28.0                           -6.0   \n",
       "12583                           -26.0                            0.0   \n",
       "12584                           -35.0                           -9.0   \n",
       "12585                           -38.0                          -19.0   \n",
       "12586                           -31.0                          -12.0   \n",
       "...                               ...                            ...   \n",
       "29557                           -23.0                           -9.0   \n",
       "29558                           -16.0                           -1.0   \n",
       "29559                           -17.0                           -9.0   \n",
       "29560                           -17.0                           -3.0   \n",
       "29561                           -26.0                          -10.0   \n",
       "\n",
       "       mobility_parks  mobility_residential  mobility_workplaces  smoothed_d2  \\\n",
       "12582             2.0                  17.0                -39.0     3.880952   \n",
       "12583            49.0                  17.0                -40.0     2.785714   \n",
       "12584            78.0                  11.0                -25.0     2.642857   \n",
       "12585            17.0                  10.0                -30.0    11.309524   \n",
       "12586           -49.0                  19.0                -45.0    11.071429   \n",
       "...               ...                   ...                  ...          ...   \n",
       "29557            98.0                  14.0                -35.0   245.380952   \n",
       "29558           144.0                   4.0                 -6.0   179.880952   \n",
       "29559           114.0                   3.0                -10.0   -96.523810   \n",
       "29560            74.0                  12.0                -32.0  -322.095238   \n",
       "29561            32.0                  15.0                -36.0  -336.428571   \n",
       "\n",
       "        x0_mean  ...   x7_amax   x8_mean   x8_amin   x8_amax   x9_mean  \\\n",
       "12582 -0.815314  ...  0.762621 -0.290963 -0.987737  0.032615 -0.376480   \n",
       "12583 -1.417909  ...  0.860248  0.550598 -0.238915  1.072211 -0.201743   \n",
       "12584  0.907826  ...  1.432990 -0.418361 -1.100802  0.766658  0.034947   \n",
       "12585  1.074053  ...  0.858769 -1.154608 -1.715199 -0.941215  0.829711   \n",
       "12586  1.614494  ...  1.974859 -0.561181 -1.704962  0.777859  0.254482   \n",
       "...         ...  ...       ...       ...       ...       ...       ...   \n",
       "29557  0.374379  ...  0.245586  0.285412 -0.105664  0.863202 -0.217611   \n",
       "29558 -0.200847  ... -0.812017  0.697624  0.464090  0.950370  0.101097   \n",
       "29559  0.671859  ... -0.587159  0.753704  0.416389  1.219656  0.332824   \n",
       "29560  1.186025  ... -0.314402  0.924094  0.587659  1.672445  0.053305   \n",
       "29561  0.083716  ... -0.744316  1.504519  1.236295  2.151778 -0.351406   \n",
       "\n",
       "        x9_amin   x9_amax  x10_mean  x10_amin  x10_amax  \n",
       "12582 -0.833365  0.210322  0.481506 -0.215669  1.328427  \n",
       "12583 -0.840541  0.407437  0.070182 -0.885137  0.932346  \n",
       "12584 -0.495268  0.470400 -0.747065 -1.050835 -0.306901  \n",
       "12585  0.320043  1.218661 -0.731472 -1.216402  0.030832  \n",
       "12586 -0.507295  0.935299 -0.212581 -1.210952  0.418377  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "29557 -0.801242  0.307856  0.241920 -0.126822  0.736519  \n",
       "29558 -0.132406  0.507043  0.568914  0.204780  0.828934  \n",
       "29559 -0.363286  0.880683  0.157192 -0.286517  0.703741  \n",
       "29560 -0.199086  0.431580 -0.046998 -0.446054  0.140200  \n",
       "29561 -1.682168  0.331051  0.279994 -0.082663  0.622010  \n",
       "\n",
       "[34521 rows x 42 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>shapeID</th>\n      <th>date</th>\n      <th>mobility_transit_stations</th>\n      <th>mobility_retail_and_recreation</th>\n      <th>mobility_grocery_and_pharmacy</th>\n      <th>mobility_parks</th>\n      <th>mobility_residential</th>\n      <th>mobility_workplaces</th>\n      <th>smoothed_d2</th>\n      <th>x0_mean</th>\n      <th>...</th>\n      <th>x7_amax</th>\n      <th>x8_mean</th>\n      <th>x8_amin</th>\n      <th>x8_amax</th>\n      <th>x9_mean</th>\n      <th>x9_amin</th>\n      <th>x9_amax</th>\n      <th>x10_mean</th>\n      <th>x10_amin</th>\n      <th>x10_amax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12582</th>\n      <td>10003</td>\n      <td>2020-03-29</td>\n      <td>-42.0</td>\n      <td>-28.0</td>\n      <td>-6.0</td>\n      <td>2.0</td>\n      <td>17.0</td>\n      <td>-39.0</td>\n      <td>3.880952</td>\n      <td>-0.815314</td>\n      <td>...</td>\n      <td>0.762621</td>\n      <td>-0.290963</td>\n      <td>-0.987737</td>\n      <td>0.032615</td>\n      <td>-0.376480</td>\n      <td>-0.833365</td>\n      <td>0.210322</td>\n      <td>0.481506</td>\n      <td>-0.215669</td>\n      <td>1.328427</td>\n    </tr>\n    <tr>\n      <th>12583</th>\n      <td>10003</td>\n      <td>2020-03-30</td>\n      <td>-39.0</td>\n      <td>-26.0</td>\n      <td>0.0</td>\n      <td>49.0</td>\n      <td>17.0</td>\n      <td>-40.0</td>\n      <td>2.785714</td>\n      <td>-1.417909</td>\n      <td>...</td>\n      <td>0.860248</td>\n      <td>0.550598</td>\n      <td>-0.238915</td>\n      <td>1.072211</td>\n      <td>-0.201743</td>\n      <td>-0.840541</td>\n      <td>0.407437</td>\n      <td>0.070182</td>\n      <td>-0.885137</td>\n      <td>0.932346</td>\n    </tr>\n    <tr>\n      <th>12584</th>\n      <td>10003</td>\n      <td>2020-03-31</td>\n      <td>-40.0</td>\n      <td>-35.0</td>\n      <td>-9.0</td>\n      <td>78.0</td>\n      <td>11.0</td>\n      <td>-25.0</td>\n      <td>2.642857</td>\n      <td>0.907826</td>\n      <td>...</td>\n      <td>1.432990</td>\n      <td>-0.418361</td>\n      <td>-1.100802</td>\n      <td>0.766658</td>\n      <td>0.034947</td>\n      <td>-0.495268</td>\n      <td>0.470400</td>\n      <td>-0.747065</td>\n      <td>-1.050835</td>\n      <td>-0.306901</td>\n    </tr>\n    <tr>\n      <th>12585</th>\n      <td>10003</td>\n      <td>2020-04-01</td>\n      <td>-56.0</td>\n      <td>-38.0</td>\n      <td>-19.0</td>\n      <td>17.0</td>\n      <td>10.0</td>\n      <td>-30.0</td>\n      <td>11.309524</td>\n      <td>1.074053</td>\n      <td>...</td>\n      <td>0.858769</td>\n      <td>-1.154608</td>\n      <td>-1.715199</td>\n      <td>-0.941215</td>\n      <td>0.829711</td>\n      <td>0.320043</td>\n      <td>1.218661</td>\n      <td>-0.731472</td>\n      <td>-1.216402</td>\n      <td>0.030832</td>\n    </tr>\n    <tr>\n      <th>12586</th>\n      <td>10003</td>\n      <td>2020-04-02</td>\n      <td>-52.0</td>\n      <td>-31.0</td>\n      <td>-12.0</td>\n      <td>-49.0</td>\n      <td>19.0</td>\n      <td>-45.0</td>\n      <td>11.071429</td>\n      <td>1.614494</td>\n      <td>...</td>\n      <td>1.974859</td>\n      <td>-0.561181</td>\n      <td>-1.704962</td>\n      <td>0.777859</td>\n      <td>0.254482</td>\n      <td>-0.507295</td>\n      <td>0.935299</td>\n      <td>-0.212581</td>\n      <td>-1.210952</td>\n      <td>0.418377</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29557</th>\n      <td>55133</td>\n      <td>2020-11-16</td>\n      <td>-31.0</td>\n      <td>-23.0</td>\n      <td>-9.0</td>\n      <td>98.0</td>\n      <td>14.0</td>\n      <td>-35.0</td>\n      <td>245.380952</td>\n      <td>0.374379</td>\n      <td>...</td>\n      <td>0.245586</td>\n      <td>0.285412</td>\n      <td>-0.105664</td>\n      <td>0.863202</td>\n      <td>-0.217611</td>\n      <td>-0.801242</td>\n      <td>0.307856</td>\n      <td>0.241920</td>\n      <td>-0.126822</td>\n      <td>0.736519</td>\n    </tr>\n    <tr>\n      <th>29558</th>\n      <td>55133</td>\n      <td>2020-11-17</td>\n      <td>-34.5</td>\n      <td>-16.0</td>\n      <td>-1.0</td>\n      <td>144.0</td>\n      <td>4.0</td>\n      <td>-6.0</td>\n      <td>179.880952</td>\n      <td>-0.200847</td>\n      <td>...</td>\n      <td>-0.812017</td>\n      <td>0.697624</td>\n      <td>0.464090</td>\n      <td>0.950370</td>\n      <td>0.101097</td>\n      <td>-0.132406</td>\n      <td>0.507043</td>\n      <td>0.568914</td>\n      <td>0.204780</td>\n      <td>0.828934</td>\n    </tr>\n    <tr>\n      <th>29559</th>\n      <td>55133</td>\n      <td>2020-11-18</td>\n      <td>-38.0</td>\n      <td>-17.0</td>\n      <td>-9.0</td>\n      <td>114.0</td>\n      <td>3.0</td>\n      <td>-10.0</td>\n      <td>-96.523810</td>\n      <td>0.671859</td>\n      <td>...</td>\n      <td>-0.587159</td>\n      <td>0.753704</td>\n      <td>0.416389</td>\n      <td>1.219656</td>\n      <td>0.332824</td>\n      <td>-0.363286</td>\n      <td>0.880683</td>\n      <td>0.157192</td>\n      <td>-0.286517</td>\n      <td>0.703741</td>\n    </tr>\n    <tr>\n      <th>29560</th>\n      <td>55133</td>\n      <td>2020-11-19</td>\n      <td>-26.0</td>\n      <td>-17.0</td>\n      <td>-3.0</td>\n      <td>74.0</td>\n      <td>12.0</td>\n      <td>-32.0</td>\n      <td>-322.095238</td>\n      <td>1.186025</td>\n      <td>...</td>\n      <td>-0.314402</td>\n      <td>0.924094</td>\n      <td>0.587659</td>\n      <td>1.672445</td>\n      <td>0.053305</td>\n      <td>-0.199086</td>\n      <td>0.431580</td>\n      <td>-0.046998</td>\n      <td>-0.446054</td>\n      <td>0.140200</td>\n    </tr>\n    <tr>\n      <th>29561</th>\n      <td>55133</td>\n      <td>2020-11-20</td>\n      <td>-29.0</td>\n      <td>-26.0</td>\n      <td>-10.0</td>\n      <td>32.0</td>\n      <td>15.0</td>\n      <td>-36.0</td>\n      <td>-336.428571</td>\n      <td>0.083716</td>\n      <td>...</td>\n      <td>-0.744316</td>\n      <td>1.504519</td>\n      <td>1.236295</td>\n      <td>2.151778</td>\n      <td>-0.351406</td>\n      <td>-1.682168</td>\n      <td>0.331051</td>\n      <td>0.279994</td>\n      <td>-0.082663</td>\n      <td>0.622010</td>\n    </tr>\n  </tbody>\n</table>\n<p>34521 rows × 42 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "DATA_PATH = \"../../data_processed/usa_urban_final.csv\"\n",
    "df = pd.read_csv(DATA_PATH, index_col=\"Unnamed: 0\")\n",
    "\n",
    "df.drop(labels=['smoothed_cumul', 'smoothed_d1'], axis=1, inplace=True)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True)\n",
    "\n",
    "df = df.sort_values(['shapeID', 'date'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            shapeID  mobility_transit_stations  \\\n",
       "count  34521.000000               34521.000000   \n",
       "mean   31559.012833                 -31.787717   \n",
       "std    12914.751288                  22.115407   \n",
       "min    10003.000000                 -89.000000   \n",
       "33%    24510.000000                 -42.000000   \n",
       "50%    34017.000000                 -32.000000   \n",
       "66%    37119.000000                 -24.000000   \n",
       "max    55133.000000                 141.000000   \n",
       "\n",
       "       mobility_retail_and_recreation  mobility_grocery_and_pharmacy  \\\n",
       "count                    34521.000000                   34521.000000   \n",
       "mean                       -22.116997                      -6.993742   \n",
       "std                         15.686999                       9.908407   \n",
       "min                        -89.000000                     -63.000000   \n",
       "33%                        -25.000000                     -10.000000   \n",
       "50%                        -19.000000                      -7.000000   \n",
       "66%                        -14.000000                      -3.000000   \n",
       "max                         25.000000                      62.000000   \n",
       "\n",
       "       mobility_parks  mobility_residential  mobility_workplaces  \\\n",
       "count    34521.000000          34521.000000         34521.000000   \n",
       "mean        51.424385             11.353976           -34.656539   \n",
       "std         70.324777              6.898706            15.197313   \n",
       "min        -86.000000             -7.000000           -83.000000   \n",
       "33%         13.000000              8.000000           -41.000000   \n",
       "50%         41.000000             11.000000           -36.000000   \n",
       "66%         70.000000             13.000000           -31.000000   \n",
       "max        658.000000             38.000000             8.000000   \n",
       "\n",
       "        smoothed_d2       x0_mean       x0_amin  ...       x7_amax  \\\n",
       "count  34521.000000  34521.000000  34521.000000  ...  34521.000000   \n",
       "mean       0.663647     -0.900682     -1.952420  ...      0.281898   \n",
       "std       36.716786      1.691739      1.619294  ...      0.972265   \n",
       "min    -1597.738095    -17.742811    -19.162831  ...     -2.206789   \n",
       "33%       -2.785714     -1.752812     -2.749990  ...     -0.238520   \n",
       "50%        0.714286     -0.989259     -2.063061  ...      0.241745   \n",
       "66%        4.166667     -0.228442     -1.342826  ...      0.620089   \n",
       "max     1594.142857      8.472449      4.212593  ...     11.113996   \n",
       "\n",
       "            x8_mean       x8_amin       x8_amax       x9_mean       x9_amin  \\\n",
       "count  34521.000000  34521.000000  34521.000000  34521.000000  34521.000000   \n",
       "mean       0.075240     -0.338583      0.537464      0.037097     -0.422045   \n",
       "std        0.736304      0.759404      0.815128      0.698473      0.793417   \n",
       "min       -3.211431     -4.438735     -2.638421     -2.814116     -4.285868   \n",
       "33%       -0.260865     -0.666161      0.157100     -0.238610     -0.715788   \n",
       "50%        0.055830     -0.341265      0.496525      0.066970     -0.371546   \n",
       "66%        0.364892     -0.036693      0.823879      0.337154     -0.069670   \n",
       "max        3.129203      2.598948      8.735262      2.851894      2.403462   \n",
       "\n",
       "            x9_amax      x10_mean      x10_amin      x10_amax  \n",
       "count  34521.000000  34521.000000  34521.000000  34521.000000  \n",
       "mean       0.481167     -0.279378     -0.742525      0.215226  \n",
       "std        0.807862      0.631255      0.640753      0.759986  \n",
       "min       -2.554283     -2.633347     -3.427467     -2.387668  \n",
       "33%        0.173939     -0.534585     -1.003849     -0.087902  \n",
       "50%        0.474984     -0.257203     -0.731698      0.211711  \n",
       "66%        0.754070     -0.016043     -0.474995      0.492962  \n",
       "max       15.844432      3.286648      2.725306     10.287810  \n",
       "\n",
       "[8 rows x 41 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>shapeID</th>\n      <th>mobility_transit_stations</th>\n      <th>mobility_retail_and_recreation</th>\n      <th>mobility_grocery_and_pharmacy</th>\n      <th>mobility_parks</th>\n      <th>mobility_residential</th>\n      <th>mobility_workplaces</th>\n      <th>smoothed_d2</th>\n      <th>x0_mean</th>\n      <th>x0_amin</th>\n      <th>...</th>\n      <th>x7_amax</th>\n      <th>x8_mean</th>\n      <th>x8_amin</th>\n      <th>x8_amax</th>\n      <th>x9_mean</th>\n      <th>x9_amin</th>\n      <th>x9_amax</th>\n      <th>x10_mean</th>\n      <th>x10_amin</th>\n      <th>x10_amax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>...</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n      <td>34521.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>31559.012833</td>\n      <td>-31.787717</td>\n      <td>-22.116997</td>\n      <td>-6.993742</td>\n      <td>51.424385</td>\n      <td>11.353976</td>\n      <td>-34.656539</td>\n      <td>0.663647</td>\n      <td>-0.900682</td>\n      <td>-1.952420</td>\n      <td>...</td>\n      <td>0.281898</td>\n      <td>0.075240</td>\n      <td>-0.338583</td>\n      <td>0.537464</td>\n      <td>0.037097</td>\n      <td>-0.422045</td>\n      <td>0.481167</td>\n      <td>-0.279378</td>\n      <td>-0.742525</td>\n      <td>0.215226</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>12914.751288</td>\n      <td>22.115407</td>\n      <td>15.686999</td>\n      <td>9.908407</td>\n      <td>70.324777</td>\n      <td>6.898706</td>\n      <td>15.197313</td>\n      <td>36.716786</td>\n      <td>1.691739</td>\n      <td>1.619294</td>\n      <td>...</td>\n      <td>0.972265</td>\n      <td>0.736304</td>\n      <td>0.759404</td>\n      <td>0.815128</td>\n      <td>0.698473</td>\n      <td>0.793417</td>\n      <td>0.807862</td>\n      <td>0.631255</td>\n      <td>0.640753</td>\n      <td>0.759986</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>10003.000000</td>\n      <td>-89.000000</td>\n      <td>-89.000000</td>\n      <td>-63.000000</td>\n      <td>-86.000000</td>\n      <td>-7.000000</td>\n      <td>-83.000000</td>\n      <td>-1597.738095</td>\n      <td>-17.742811</td>\n      <td>-19.162831</td>\n      <td>...</td>\n      <td>-2.206789</td>\n      <td>-3.211431</td>\n      <td>-4.438735</td>\n      <td>-2.638421</td>\n      <td>-2.814116</td>\n      <td>-4.285868</td>\n      <td>-2.554283</td>\n      <td>-2.633347</td>\n      <td>-3.427467</td>\n      <td>-2.387668</td>\n    </tr>\n    <tr>\n      <th>33%</th>\n      <td>24510.000000</td>\n      <td>-42.000000</td>\n      <td>-25.000000</td>\n      <td>-10.000000</td>\n      <td>13.000000</td>\n      <td>8.000000</td>\n      <td>-41.000000</td>\n      <td>-2.785714</td>\n      <td>-1.752812</td>\n      <td>-2.749990</td>\n      <td>...</td>\n      <td>-0.238520</td>\n      <td>-0.260865</td>\n      <td>-0.666161</td>\n      <td>0.157100</td>\n      <td>-0.238610</td>\n      <td>-0.715788</td>\n      <td>0.173939</td>\n      <td>-0.534585</td>\n      <td>-1.003849</td>\n      <td>-0.087902</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>34017.000000</td>\n      <td>-32.000000</td>\n      <td>-19.000000</td>\n      <td>-7.000000</td>\n      <td>41.000000</td>\n      <td>11.000000</td>\n      <td>-36.000000</td>\n      <td>0.714286</td>\n      <td>-0.989259</td>\n      <td>-2.063061</td>\n      <td>...</td>\n      <td>0.241745</td>\n      <td>0.055830</td>\n      <td>-0.341265</td>\n      <td>0.496525</td>\n      <td>0.066970</td>\n      <td>-0.371546</td>\n      <td>0.474984</td>\n      <td>-0.257203</td>\n      <td>-0.731698</td>\n      <td>0.211711</td>\n    </tr>\n    <tr>\n      <th>66%</th>\n      <td>37119.000000</td>\n      <td>-24.000000</td>\n      <td>-14.000000</td>\n      <td>-3.000000</td>\n      <td>70.000000</td>\n      <td>13.000000</td>\n      <td>-31.000000</td>\n      <td>4.166667</td>\n      <td>-0.228442</td>\n      <td>-1.342826</td>\n      <td>...</td>\n      <td>0.620089</td>\n      <td>0.364892</td>\n      <td>-0.036693</td>\n      <td>0.823879</td>\n      <td>0.337154</td>\n      <td>-0.069670</td>\n      <td>0.754070</td>\n      <td>-0.016043</td>\n      <td>-0.474995</td>\n      <td>0.492962</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>55133.000000</td>\n      <td>141.000000</td>\n      <td>25.000000</td>\n      <td>62.000000</td>\n      <td>658.000000</td>\n      <td>38.000000</td>\n      <td>8.000000</td>\n      <td>1594.142857</td>\n      <td>8.472449</td>\n      <td>4.212593</td>\n      <td>...</td>\n      <td>11.113996</td>\n      <td>3.129203</td>\n      <td>2.598948</td>\n      <td>8.735262</td>\n      <td>2.851894</td>\n      <td>2.403462</td>\n      <td>15.844432</td>\n      <td>3.286648</td>\n      <td>2.725306</td>\n      <td>10.287810</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.describe(percentiles=[0.33,0.66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.08274026858097655 0.7531716071539081 0.1640881242651154\n0.3333333333333333 0.3333333333333333 0.3333333333333333\n8022\n8022\n"
     ]
    }
   ],
   "source": [
    "N_DAYS = 7\n",
    "d2_threshold = 6.0\n",
    "data_x = []\n",
    "data_y = []\n",
    "x_cols = []\n",
    "#x_cols = [\"mobility_transit_stations\",\"mobility_retail_and_recreation\",\"mobility_grocery_and_pharmacy\",\"mobility_parks\",\"mobility_residential\",\"mobility_workplaces\"] # Mobility data\n",
    "for i in range(11): # CAMS data\n",
    "    x_cols.extend([\"x{:n}_mean\".format(i)]) #\"x{:n}_mean\".format(i),\"x{:n}_amin\".format(i),\n",
    "\n",
    "x_labels = []\n",
    "\n",
    "for group,group_df in df.groupby(by=[\"shapeID\"]):\n",
    "    dates = group_df[\"date\"]\n",
    "    x = group_df[x_cols].values\n",
    "    y = group_df[\"smoothed_d2\"].values\n",
    "    for i in range(len(x)-7):\n",
    "        if (dates.iloc[i+6] - dates.iloc[i]).days == N_DAYS - 1:\n",
    "            x_labels.append((str(group),dates.iloc[i],dates.iloc[i+6]))\n",
    "            data_x.append(x[i:i+7].flatten())\n",
    "            y_period = y[i:i+7]\n",
    "            data_y.append([np.sum(y_period < -d2_threshold),np.sum(np.abs(y_period) <= d2_threshold),np.sum(y_period > d2_threshold)])\n",
    "        else:\n",
    "            i += 6\n",
    "\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y) # All equal to 7\n",
    "#print(len(data_x),len(data_y),np.sum(np.sum(data_y,axis=1) != 7))\n",
    "x_labels = np.array(x_labels)\n",
    "\n",
    "data_y = data_y.astype(float) / 7.0\n",
    "\n",
    "\n",
    "class_references = [\n",
    "    -np.log(np.array([ # Decelerating\n",
    "        [0.98,0.01,0.01],\n",
    "        [0.7,0.2,0.1]\n",
    "    ])),\n",
    "    -np.log(np.array([ # Stable\n",
    "        [0.33,0.34,0.33],\n",
    "        [0.495,0.01,0.495],\n",
    "        [0.1,0.8,0.1],\n",
    "        [0.01,0.98,0.01]\n",
    "    ])),\n",
    "    -np.log(np.array([ # Accelerating\n",
    "        [0.01,0.01,0.98],\n",
    "        [0.1,0.2,0.7]\n",
    "    ]))\n",
    "]\n",
    "\n",
    "# Minimize cross-entropy of class reference distributions \n",
    "data_y_mapped = np.array(list(map(lambda x : np.argmin([np.min(np.sum(x*class_references[i],axis=1)) for i in range(len(class_references))]),data_y)))\n",
    "#print(data_y[data_y_mapped == 0][:10])\n",
    "#print(data_y[data_y_mapped == 1][:10])\n",
    "#print(data_y[data_y[:,1] < 0.15][:10])\n",
    "#print(data_y_mapped[data_y[:,1] < 0.15][:10])\n",
    "#print(data_y[data_y_mapped == 2][:10])\n",
    "print(len(data_y_mapped[data_y_mapped == 0])/len(data_y_mapped),len(data_y_mapped[data_y_mapped == 1])/len(data_y_mapped),len(data_y_mapped[data_y_mapped == 2])/len(data_y_mapped))\n",
    "\n",
    "dat = np.arange(len(data_y_mapped))\n",
    "decel = dat[data_y_mapped == 0]\n",
    "accel = dat[data_y_mapped == 2]\n",
    "np.random.shuffle(accel)\n",
    "accel = accel[:len(decel)]\n",
    "stabl = dat[data_y_mapped == 1]\n",
    "np.random.shuffle(stabl)\n",
    "stabl = stabl[:len(decel)]\n",
    "\n",
    "dat = np.append(decel,np.append(stabl,accel))\n",
    "np.random.shuffle(dat)\n",
    "\n",
    "data_x = data_x[dat]\n",
    "data_y_mapped = data_y_mapped[dat]\n",
    "x_labels = x_labels[dat]\n",
    "\n",
    "print(len(data_y_mapped[data_y_mapped == 0])/len(data_y_mapped),len(data_y_mapped[data_y_mapped == 1])/len(data_y_mapped),len(data_y_mapped[data_y_mapped == 2])/len(data_y_mapped))\n",
    "print(len(data_y_mapped))\n",
    "print(len(x_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.sum(data_x != data_x) > 0: # Count NaNs\n",
    "    raise Exception(\"This data contains NaNs.\")"
   ]
  },
  {
   "source": [
    "```\n",
    "ids = df[\"shapeID\"].drop_duplicates().values\n",
    "\n",
    "N_DAYS = 7\n",
    "times = df[\"time\"].drop_duplicates().values\n",
    "times_grouped = [times[n:n+N_DAYS] for n in range(0, len(times), N_DAYS)]\n",
    "times_grouped.pop() # not len 14\n",
    "\n",
    "cols = df.drop(['time', 'shapeID', 'smoothed_d2'], axis=1).columns\n",
    "grouped_cols = []\n",
    "for i in range(0, N_DAYS):\n",
    "    for label in cols:\n",
    "        grouped_cols.append('Day {}: {}'.format(i, label))\n",
    "\n",
    "X_grouped = pd.DataFrame(columns=grouped_cols)\n",
    "Y_grouped = pd.DataFrame(columns=['y{}'.format(i) for i in range(0,N_DAYS)])\n",
    "\n",
    "errors = []\n",
    "bad_format_error = 0\n",
    "for id in ids:\n",
    "    for dates in times_grouped:\n",
    "\n",
    "        id_query = df.shapeID == id\n",
    "        date_query = df.time.isin(dates)\n",
    "        query = df[id_query & date_query].drop(['time', 'shapeID'], axis=1)\n",
    "        \n",
    "        x_vals = query.drop('smoothed_d2', axis=1).values.flatten()\n",
    "        y_vals = query.smoothed_d2.values.flatten()\n",
    "\n",
    "        if(len(x_vals)) != len(grouped_cols):\n",
    "            bad_format_error+=1\n",
    "            errors.append(query)\n",
    "        else:\n",
    "            df_x_temp = pd.DataFrame(x_vals.reshape(1,-1), columns=grouped_cols)\n",
    "            df_y_temp = pd.DataFrame(y_vals.reshape(1,-1), columns=['y{}'.format(i) for i in range(0,N_DAYS)])\n",
    "            X_grouped = X_grouped.append(df_x_temp, ignore_index=True)\n",
    "            Y_grouped = Y_grouped.append(df_y_temp, ignore_index=True)\n",
    "print(\"SUCCESS with {}/{} FORMAT_ERRORS\".format(bad_format_error, len(ids) * len(times_grouped)))\n",
    "X_grouped\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "```\n",
    "N_PCs = 11\n",
    "avg_cols = [\"x{}_mean\".format(i) for i in range(0,N_PCs)]\n",
    "min_cols = [\"x{}_amin\".format(i) for i in range(0,N_PCs)]\n",
    "max_cols = [\"x{}_amax\".format(i) for i in range(0,N_PCs)]\n",
    "generic_cols = ['time', 'shapeID', 'mobility_transit_stations', 'mobility_retail_and_recreation',\n",
    "       'mobility_grocery_and_pharmacy', 'mobility_parks',\n",
    "       'mobility_residential', 'mobility_workplaces']\n",
    "\n",
    "def get_df_from_cols(dataframe, cols):\n",
    "    X_new = pd.DataFrame()\n",
    "    for column in dataframe.columns:\n",
    "        for label in cols:\n",
    "            if label in column:\n",
    "                X_new[column] = dataframe[column]\n",
    "    return X_new\n",
    "\n",
    "X_no_cams = get_df_from_cols(X_grouped, generic_cols)\n",
    "X_min = get_df_from_cols(X_grouped, min_cols+generic_cols)\n",
    "X_max = get_df_from_cols(X_grouped, max_cols+generic_cols)\n",
    "X_avg = get_df_from_cols(X_grouped, avg_cols+generic_cols)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DT -2937.549588 1352.933767 \n",
      "KNN -1483.987277 1304.749986 \n",
      "LR -1290.123501 1250.325647 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.ensemble import AdaBoostRegressor \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train = X_no_cams.to_numpy()\n",
    "y_train = Y_grouped.mean().to_numpy()\n",
    "\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "models = []\n",
    "models.append(('GB', GradientBoostingRegressor()))\n",
    "models.append(('AB', AdaBoostRegressor()))\n",
    "models.append(('DT', DecisionTreeRegressor()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('LR', LinearRegression()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s %f %f \" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "source": [
    "Results: no difference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GB 0.530381 0.012139 \n",
      "AB 0.488989 0.014139 \n",
      "DT 0.472614 0.015494 \n",
      "KNN5 0.560126 0.013314 \n",
      "LR 0.489331 0.012373 \n",
      "[array([0.54262673, 0.54493088, 0.50576037, 0.53056517, 0.53402537,\n",
      "       0.5455594 , 0.52018454, 0.53517878, 0.52018454, 0.52479815]), array([0.50576037, 0.48502304, 0.47235023, 0.46366782, 0.49134948,\n",
      "       0.50865052, 0.47981546, 0.50634371, 0.48673587, 0.49019608]), array([0.47235023, 0.50115207, 0.46428571, 0.45098039, 0.45790081,\n",
      "       0.49480969, 0.46597463, 0.48442907, 0.46020761, 0.47404844]), array([0.55760369, 0.57488479, 0.57834101, 0.55594002, 0.55363322,\n",
      "       0.57093426, 0.544406  , 0.57670127, 0.54094579, 0.54786621]), array([0.50806452, 0.50345622, 0.48732719, 0.49250288, 0.50288351,\n",
      "       0.48788927, 0.48558247, 0.47174164, 0.46828143, 0.48558247])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(data_x,data_y_mapped,test_size=0.2)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#TRESHOLD = 10\n",
    "\n",
    "#X_train = X_min.to_numpy()\n",
    "#y_train = (Y_grouped > TRESHOLD).sum(axis=1)\n",
    "\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "models = []\n",
    "models.append(('GB', GradientBoostingClassifier()))\n",
    "models.append(('AB', AdaBoostClassifier()))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('KNN5', KNeighborsClassifier()))\n",
    "#models.append(('KNN6', KNeighborsClassifier(n_neighbors=6)))\n",
    "#models.append(('KNN7', KNeighborsClassifier(n_neighbors=7)))\n",
    "#models.append(('KNN8', KNeighborsClassifier(n_neighbors=8)))\n",
    "#models.append(('KNN9', KNeighborsClassifier(n_neighbors=9)))\n",
    "#models.append(('KNN10', KNeighborsClassifier(n_neighbors=10)))\n",
    "models.append(('LR', LogisticRegression()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s %f %f \" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "source": [
    "Mobility :\n",
    "- GB 0.521731 0.020419 \n",
    "- AB 0.464854 0.021199 \n",
    "- DT 0.445842 0.014300 \n",
    "- KNN 0.477953 0.011020 \n",
    "- LR 0.433846 0.017263\n",
    "\n",
    "\n",
    "Mobility + CAMS (mean) : \n",
    "- GB 0.585315 0.021577 \n",
    "- AB 0.523920 0.016988 \n",
    "- DT 0.503976 0.022049 \n",
    "- KNN 0.482482 0.025346 \n",
    "- LR 0.524232 0.022335\n",
    "\n",
    "\n",
    "CAMS only:\n",
    "- GB 0.570983 0.017125 \n",
    "- AB 0.498513 0.016178 \n",
    "- DT 0.491812 0.013192 \n",
    "- KNN 0.592799 0.012372 \n",
    "- LR 0.500387 0.011376\n",
    "\n",
    "\n",
    "CAMS only (first 6 PCs):\n",
    "- GB 0.553225 0.022999 \n",
    "- AB 0.489639 0.019175 \n",
    "- DT 0.479038 0.014877 \n",
    "- KNN 0.575815 0.013192 \n",
    "- LR 0.503043 0.011353\n",
    "\n",
    "\n",
    "CAMS only (max only):\n",
    "- GB 0.572539 0.016715 \n",
    "- AB 0.505224 0.015899 \n",
    "- DT 0.490577 0.028445 \n",
    "- KNN 0.591241 0.013768 \n",
    "- LR 0.503973 0.018374\n",
    "\n",
    "\n",
    "CAMS only (min only):\n",
    "- GB 0.558206 0.012808 \n",
    "- AB 0.499603 0.013846 \n",
    "- DT 0.492600 0.011840 \n",
    "- KNN 0.588752 0.019825 \n",
    "- LR 0.505990 0.017910\n",
    "\n",
    "\n",
    "CAMS only (mean only):\n",
    "- GB 0.559451 0.018181 \n",
    "- AB 0.507402 0.013728 \n",
    "- DT 0.495705 0.027473 \n",
    "- KNN 0.597318 0.014909 \n",
    "- LR 0.512234 0.018876\n",
    "\n",
    "\n",
    "CAMS only (mean only):\n",
    "\n",
    "k run 1 :\n",
    "- KNN5 0.610874 0.019984 \n",
    "- KNN10 0.607912 0.009555 \n",
    "- KNN15 0.606355 0.011807 \n",
    "- KNN20 0.605424 0.012652 \n",
    "- KNN30 0.604021 0.012731\n",
    "\n",
    "k run 2 :\n",
    "- KNN5 0.596858 0.020018 \n",
    "- KNN6 0.596081 0.015506 \n",
    "- KNN7 0.601533 0.017145 \n",
    "- KNN8 0.599196 0.013899 \n",
    "- KNN9 0.597012 0.009711 \n",
    "- KNN10 0.595767 0.012003"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "MEAN OF WEEK W HIGHER 10 CLASSIFICATION\n",
    "\n",
    "- GB 0.927965 0.019642 \n",
    "- AB 0.925721 0.020152 \n",
    "- DT 0.875234 0.026127 \n",
    "- KNN 0.924821 0.022831 \n",
    "- LR 0.927741 0.019161 \n",
    "\n",
    "(w cams)\n",
    "- GB 0.927293 0.020238 \n",
    "- AB 0.923704 0.018885 \n",
    "- DT 0.875671 0.011897 \n",
    "- KNN 0.923250 0.023082 \n",
    "- LR 0.922804 0.018741 \n",
    "\n",
    "\n",
    "\n",
    "N DAYS HIGHER 10 CLASSIFICATION\n",
    "\n",
    "- GB 0.450636 0.063706 \n",
    "- AB 0.430657 0.074770 \n",
    "- DT 0.319354 0.038397 \n",
    "- KNN 0.410910 0.041697 \n",
    "- LR 0.460284 0.067121 \n",
    "\n",
    "(w cams)\n",
    "- GB 0.455341 0.057830 \n",
    "- AB 0.442550 0.058166 \n",
    "- DT 0.346043 0.033837 \n",
    "- KNN 0.412478 0.039655 \n",
    "- LR 0.447716 0.061701 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1702127659574468 0.475177304964539 0.3546099290780142 141\n0.34138785625774476 0.35811648079306074 0.30049566294919455 3228\n0.3674418604651163 0.2651162790697674 0.3674418604651163 860\n0.4333868378812199 0.3073836276083467 0.2592295345104334 1246\n0.25 0.3398809523809524 0.4101190476190476 1680\n0.35240963855421686 0.2680722891566265 0.3795180722891566 664\n"
     ]
    }
   ],
   "source": [
    "#print(len(data_y_mapped))\n",
    "# Regional splitting\n",
    "regions = {}\n",
    "west_mask = [\"6\",\"32\",\"41\",\"53\"]\n",
    "east_mask = [\"9\",\"10\",\"11\",\"23\",\"24\",\"25\",\"34\",\"36\",\"37\",\"42\",\"44\",\"50\",\"51\"]\n",
    "south_mask = [\"1\",\"5\",\"8\",\"22\",\"35\",\"48\"]\n",
    "east_nomask = [\"12\",\"13\",\"45\"]\n",
    "middle_mask = [\"17\",\"18\",\"21\",\"26\",\"27\",\"39\",\"54\",\"55\"]\n",
    "middle_nomask = [\"16\",\"19\",\"28\",\"29\",\"31\",\"38\",\"40\",\"46\",\"47\",\"56\"]\n",
    "\n",
    "splits = []\n",
    "west_mask_split = []\n",
    "east_mask_split = []\n",
    "south_mask_split = []\n",
    "east_nomask_split = []\n",
    "middle_mask_split = []\n",
    "middle_nomask_split = []\n",
    "\n",
    "for i in range(len(x_labels)):\n",
    "    state_fips = x_labels[i][0][:-3]\n",
    "    if state_fips in west_mask:\n",
    "        west_mask_split.append(i)\n",
    "    elif state_fips in east_mask:\n",
    "        east_mask_split.append(i)\n",
    "    elif state_fips in south_mask:\n",
    "        south_mask_split.append(i)\n",
    "    elif state_fips in east_nomask:\n",
    "        east_nomask_split.append(i)\n",
    "    elif state_fips in middle_mask:\n",
    "        middle_mask_split.append(i)\n",
    "    elif state_fips in middle_nomask:\n",
    "        middle_nomask_split.append(i)\n",
    "\n",
    "west_mask_split = np.array(west_mask_split)\n",
    "east_mask_split = np.array(east_mask_split)\n",
    "south_mask_split = np.array(south_mask_split)\n",
    "east_nomask_split = np.array(east_nomask_split)\n",
    "middle_mask_split = np.array(middle_mask_split)\n",
    "middle_nomask_split = np.array(middle_nomask_split)\n",
    "\n",
    "def display_split_proportions(mask):\n",
    "    tmp = data_y_mapped[mask]\n",
    "    print(np.average(tmp == 0),np.average(tmp == 1),np.average(tmp == 2),len(tmp))\n",
    "\n",
    "display_split_proportions(west_mask_split)\n",
    "display_split_proportions(east_mask_split)\n",
    "display_split_proportions(south_mask_split)\n",
    "display_split_proportions(east_nomask_split)\n",
    "display_split_proportions(middle_mask_split)\n",
    "display_split_proportions(middle_nomask_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "west_mask_knn 0.43547773125237915 0.3900709219858156\n",
      "west_mask_gbc 0.37228778073848495 0.524822695035461\n",
      "east_mask_knn 0.4213600333750521 0.5086741016109045\n",
      "east_mask_gbc 0.4025865665415102 0.49876084262701365\n",
      "south_mask_knn 0.40589220888020106 0.3872093023255814\n",
      "south_mask_gbc 0.3821558223959788 0.3883720930232558\n",
      "east_no_mask_knn 0.34371310507674147 0.37640449438202245\n",
      "east_no_mask_gbc 0.3572904368358914 0.3996789727126806\n",
      "middle_mask_knn 0.4495427309996846 0.5238095238095238\n",
      "middle_mask_gbc 0.4421318196152633 0.5172619047619048\n",
      "middle_no_mask_knn 0.41709703723838 0.4292168674698795\n",
      "middle_no_mask_gbc 0.4149225332970916 0.37349397590361444\n",
      "0.4132332263984654 0.033118352525934334\n",
      "0.46860212303363596 0.06036529300484583\n",
      "0.4021191871724127 0.027168577630856155\n",
      "0.46463742166517463 0.056201990661977015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(classes,y_pred,y,savepath=None):\n",
    "    if len(y) != len(y_pred):\n",
    "        raise Exception(\"Truth and prediction do not have equal length.\")\n",
    "    class_index = {}\n",
    "    for i in range(len(classes)):\n",
    "        class_index[classes[i]] = i\n",
    "    \n",
    "    mat = np.zeros((len(classes),len(classes)))\n",
    "    for i in range(len(y)):\n",
    "        mat[class_index[y[i]]][class_index[y_pred[i]]] += 1\n",
    "    \n",
    "    for i in range(len(mat)):\n",
    "        mat[i] /= np.sum(mat[i])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(mat,cmap=\"rainbow\",vmin=0.0,vmax=1.0)\n",
    "\n",
    "    ax.set_xticks(range(len(classes)))\n",
    "    ax.set_yticks(range(len(classes)))\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    #plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "    #        rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    #for i in y:\n",
    "    #    for j in x:\n",
    "    #        text = ax.text(j, i, \"{:.4f}\".format(mat[i,j]),\n",
    "    #                    ha=\"center\", va=\"center\", color=\"black\",fontsize=8)\n",
    "\n",
    "    #fig.colorbar(im)\n",
    "\n",
    "    ax.set_xlabel(\"Predicted class\")\n",
    "    ax.set_ylabel(\"True class\")\n",
    "\n",
    "    fig.colorbar(im)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if savepath is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(savepath)\n",
    "    plt.close()\n",
    "\n",
    "classifier1 = KNeighborsClassifier()\n",
    "classifier2 = GradientBoostingClassifier()\n",
    "\n",
    "pos = set(range(len(data_y_mapped)))\n",
    "\n",
    "totLen = len(east_mask_split) + len(west_mask_split) + len(south_mask_split) + len(east_nomask_split) + len(middle_mask_split) + len(middle_nomask_split)\n",
    "\n",
    "weights = []\n",
    "accuracy = []\n",
    "accuracy_r = []\n",
    "\n",
    "def classify_and_display_results(x_train,y_train,x_test,y_test,classifier,outName):\n",
    "    classifier.fit(x_train,y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    classifier.fit(x_test,y_test)\n",
    "    y_pred_r = classifier.predict(x_train)\n",
    "    a = np.average(y_test == y_pred)\n",
    "    a_r = np.average(y_train == y_pred_r)\n",
    "    accuracy.append(a)\n",
    "    accuracy_r.append(a_r)\n",
    "    weights.append(len(x_train)/totLen)\n",
    "    print(outName,a,a_r)\n",
    "    plot_confusion_matrix([0,1,2],y_pred,y_test,savepath=outName + \".png\")\n",
    "    plot_confusion_matrix([0,1,2],y_pred_r,y_train,savepath=outName + \"_r.png\")\n",
    "\n",
    "\n",
    "totLen = len(east_mask_split) + len(west_mask_split) + len(south_mask_split) + len(east_nomask_split) + len(middle_mask_split) + len(middle_nomask_split)\n",
    "\n",
    "for name,split in ((\"west_mask\",west_mask_split),(\"east_mask\",east_mask_split),(\"south_mask\",south_mask_split),(\"east_no_mask\",east_nomask_split),(\"middle_mask\",middle_mask_split),(\"middle_no_mask\",middle_nomask_split)):\n",
    "    pos_train = split\n",
    "    pos_test = np.array(list(pos.difference(set(split))))\n",
    "\n",
    "    #print(pos_train[:10])\n",
    "    #print(pos_test[:10])\n",
    "\n",
    "    x_train = data_x[pos_train]\n",
    "    y_train = data_y_mapped[pos_train]\n",
    "    x_test = data_x[pos_test]\n",
    "    y_test = data_y_mapped[pos_test]\n",
    "\n",
    "    classify_and_display_results(x_train,y_train,x_test,y_test,classifier1,name + \"_knn\")\n",
    "    classify_and_display_results(x_train,y_train,x_test,y_test,classifier2,name + \"_gbc\")\n",
    "\n",
    "mean_knn = np.average(accuracy[::2],weights=weights[::2])\n",
    "mean_knn_r = np.average(accuracy_r[::2],weights=weights[::2])\n",
    "mean_gbc = np.average(accuracy[1::2],weights=weights[1::2])\n",
    "mean_gbc_r = np.average(accuracy_r[1::2],weights=weights[1::2])\n",
    "\n",
    "print(mean_knn,np.sqrt(np.average((np.array(accuracy[::2]) - mean_knn)**2,weights=weights[::2])))\n",
    "print(mean_knn_r,np.sqrt(np.average((np.array(accuracy_r[::2]) - mean_knn_r)**2,weights=weights[::2])))\n",
    "print(mean_gbc,np.sqrt(np.average((np.array(accuracy[1::2]) - mean_gbc)**2,weights=weights[1::2])))\n",
    "print(mean_gbc_r,np.sqrt(np.average((np.array(accuracy_r[1::2]) - mean_gbc_r)**2,weights=weights[1::2])))"
   ]
  },
  {
   "source": [
    "Predictions using mobility only\n",
    "- west_mask_knn 0.3860695255011418 0.24285714285714285\n",
    "- west_mask_gbc 0.359172798782035 0.32142857142857145\n",
    "- east_mask_knn 0.3784679089026915 0.4467418546365915\n",
    "- east_mask_gbc 0.4062111801242236 0.47775689223057644\n",
    "- south_mask_knn 0.38040587823652905 0.3751425313568985\n",
    "- south_mask_gbc 0.3885234429671099 0.40022805017103763\n",
    "- east_no_mask_knn 0.37196206283343214 0.4050235478806907\n",
    "- east_no_mask_gbc 0.40411973918197985 0.34301412872841447\n",
    "- middle_mask_knn 0.38682084587359417 0.3856056173200702\n",
    "- middle_mask_gbc 0.4268968794550927 0.5002925687536571\n",
    "- middle_no_mask_knn 0.3321564367191744 0.3860182370820669\n",
    "- middle_no_mask_gbc 0.3661053775122216 0.36322188449848025\n",
    "\n",
    "Predictions using mobility + CAMS (mean only):\n",
    "- west_mask_knn 0.4028941355674029 0.3125\n",
    "- west_mask_gbc 0.39756283320639757 0.4513888888888889\n",
    "- east_mask_knn 0.3752069536423841 0.43855799373040755\n",
    "- east_mask_gbc 0.4236341059602649 0.5360501567398119\n",
    "- south_mask_knn 0.3610411418975651 0.3641552511415525\n",
    "- south_mask_gbc 0.382031905961377 0.3550228310502283\n",
    "- east_no_mask_knn 0.38164538164538164 0.3781055900621118\n",
    "- east_no_mask_gbc 0.41847341847341846 0.41770186335403725\n",
    "- middle_mask_knn 0.3962501969434378 0.39761194029850744\n",
    "- middle_mask_gbc 0.4810146525917756 0.5438805970149254\n",
    "- middle_no_mask_knn 0.3484992530218661 0.3899848254931715\n",
    "- middle_no_mask_gbc 0.4101589026212142 0.40212443095599393\n",
    "\n",
    "Predictions using CAMS mean :\n",
    "- west_mask_knn 0.41686746987951806 0.46715328467153283\n",
    "- west_mask_gbc 0.4040583386176284 0.44525547445255476\n",
    "- east_mask_knn 0.4161825726141079 0.5237351655215491\n",
    "- east_mask_gbc 0.4099585062240664 0.5031230480949407\n",
    "- south_mask_knn 0.4073504751257686 0.3810623556581986\n",
    "- south_mask_gbc 0.38038010061486865 0.34295612009237875\n",
    "- east_no_mask_knn 0.38438749814842244 0.3878835562549174\n",
    "- east_no_mask_gbc 0.3901644200859132 0.3870967741935484\n",
    "- middle_mask_knn 0.4542020774315392 0.526378896882494\n",
    "- middle_mask_gbc 0.4446018256216557 0.5449640287769785\n",
    "- middle_no_mask_knn 0.41800380745172694 0.4565868263473054\n",
    "- middle_no_mask_gbc 0.41011694316018493 0.41916167664670656\n",
    "\n",
    "Predictions using CAMS max :\n",
    "- west mask 0.42224759005580925 0.39855072463768115\n",
    "- east mask 0.406575114440283 0.47947761194029853\n",
    "- south mask 0.385 0.40389294403892945\n",
    "- east no mask 0.37166567871962064 0.39089481946624804\n",
    "- middle mask 0.4332118523213437 0.5160724722384571\n",
    "- middle no mask 0.3960059774487162 0.43872919818456885\n",
    "\n",
    "Predictions using CAMS min :\n",
    "- west mask 0.402000506457331 0.4032258064516129\n",
    "- east mask 0.40731504571903576 0.4853582554517134\n",
    "- south mask 0.3862396867570969 0.39380022962112515\n",
    "- east no mask 0.35011848341232227 0.3409448818897638\n",
    "- middle mask 0.43080321918889064 0.5145400593471811\n",
    "- middle no mask 0.42363190852164445 0.4378698224852071\n",
    "\n",
    "Predictions using CAMS max and min :\n",
    "- west mask 0.43273372181403597 0.4296875\n",
    "- east mask 0.4157372986369269 0.49937106918238994\n",
    "- south mask 0.38004484304932734 0.40970654627539504\n",
    "- east no mask 0.3429377691964949 0.37548487199379366\n",
    "- middle mask 0.45731031205449074 0.521357519016969\n",
    "- middle no mask 0.4195690472963816 0.4510108864696734"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.08274026858097655 0.7531716071539081 0.1640881242651154\n"
     ]
    }
   ],
   "source": [
    "N_DAYS = 7\n",
    "d2_threshold = 6.0\n",
    "data_x = []\n",
    "data_y = []\n",
    "x_cols = []\n",
    "#x_cols = [\"mobility_transit_stations\",\"mobility_retail_and_recreation\",\"mobility_grocery_and_pharmacy\",\"mobility_parks\",\"mobility_residential\",\"mobility_workplaces\"] # Mobility data\n",
    "for i in range(11): # CAMS data\n",
    "    x_cols.extend([\"x{:n}_mean\".format(i)]) #\"x{:n}_mean\".format(i),\"x{:n}_amin\".format(i),\n",
    "\n",
    "x_labels = []\n",
    "\n",
    "for group,group_df in df.groupby(by=[\"shapeID\"]):\n",
    "    dates = group_df[\"date\"]\n",
    "    x = group_df[x_cols].values\n",
    "    y = group_df[\"smoothed_d2\"].values\n",
    "    for i in range(len(x)-7):\n",
    "        if (dates.iloc[i+6] - dates.iloc[i]).days == N_DAYS - 1:\n",
    "            x_labels.append((group,dates.iloc[i],dates.iloc[i+6]))\n",
    "            data_x.append(x[i:i+7].flatten())\n",
    "            y_period = y[i:i+7]\n",
    "            data_y.append([np.sum(y_period < -d2_threshold),np.sum(np.abs(y_period) <= d2_threshold),np.sum(y_period > d2_threshold)])\n",
    "        else:\n",
    "            i += 6\n",
    "\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y) # All equal to 7\n",
    "#print(len(data_x),len(data_y),np.sum(np.sum(data_y,axis=1) != 7))\n",
    "\n",
    "data_y = data_y.astype(float) / 7.0\n",
    "\n",
    "\n",
    "class_references = [\n",
    "    -np.log(np.array([ # Decelerating\n",
    "        [0.98,0.01,0.01],\n",
    "        [0.7,0.2,0.1]\n",
    "    ])),\n",
    "    -np.log(np.array([ # Stable\n",
    "        [0.33,0.34,0.33],\n",
    "        [0.495,0.01,0.495],\n",
    "        [0.1,0.8,0.1],\n",
    "        [0.01,0.98,0.01]\n",
    "    ])),\n",
    "    -np.log(np.array([ # Accelerating\n",
    "        [0.01,0.01,0.98],\n",
    "        [0.1,0.2,0.7]\n",
    "    ]))\n",
    "]\n",
    "\n",
    "# Minimize cross-entropy of class reference distributions \n",
    "data_y_mapped = np.array(list(map(lambda x : np.argmin([np.min(np.sum(x*class_references[i],axis=1)) for i in range(len(class_references))]),data_y)))\n",
    "#print(data_y[data_y_mapped == 0][:10])\n",
    "#print(data_y[data_y_mapped == 1][:10])\n",
    "#print(data_y[data_y[:,1] < 0.15][:10])\n",
    "#print(data_y_mapped[data_y[:,1] < 0.15][:10])\n",
    "#print(data_y[data_y_mapped == 2][:10])\n",
    "print(len(data_y_mapped[data_y_mapped == 0])/len(data_y_mapped),len(data_y_mapped[data_y_mapped == 1])/len(data_y_mapped),len(data_y_mapped[data_y_mapped == 2])/len(data_y_mapped))\n",
    "\n",
    "dat = np.arange(len(data_y_mapped))\n",
    "decel = dat[data_y_mapped == 0]\n",
    "accel = dat[data_y_mapped == 2]\n",
    "np.random.shuffle(accel)\n",
    "accel = accel[:len(decel)]\n",
    "stabl = dat[data_y_mapped == 1]\n",
    "np.random.shuffle(stabl)\n",
    "stabl = stabl[:len(decel)]\n",
    "\n",
    "dat = np.append(decel,np.append(stabl,accel))\n",
    "np.random.shuffle(dat)\n",
    "\n",
    "data_x_train = data_x[dat]\n",
    "data_y_mapped_train = data_y_mapped[dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "classifier.fit(data_x_train,data_y_mapped_train)\n",
    "\n",
    "y_pred = classifier.predict(data_x)\n",
    "print(np.sum(y_pred == data_y_mapped)/len(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"prediction_results.csv\",\"w\")\n",
    "\n",
    "for i in range(len(x_labels)):\n",
    "    f.write(str(x_labels[i][0]) + \",\"\n",
    "            + str(x_labels[i][1].year) + \"-\" + \"{:02n}\".format(x_labels[i][1].month) + \"-\" + \"{:02n}\".format(x_labels[i][1].day) + \",\"\n",
    "            + str(x_labels[i][2].year) + \"-\" + \"{:02n}\".format(x_labels[i][2].month) + \"-\" + \"{:02n}\".format(x_labels[i][2].day) + \",\"\n",
    "            + str(y_pred[i]) + \",\" + str(data_y_mapped[i]) + \"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "x_labels[i][1].year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}